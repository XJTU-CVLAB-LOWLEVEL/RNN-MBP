{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## About how to train your own dataset\n",
    "\n",
    "It's optional to use lmdb format or ordinary format."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Ordinary format\n",
    "\n",
    "Please copy the code of '/data/BSD/py' to create your dataset file '[dataset].py' and modify '\\_generate_samples()' function according to your directory structure."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Lmdb format\n",
    "\n",
    "Here, we take GOPRO-DS as example.\n",
    "\n",
    "First, download and unzip the source dataset [\"*gopro_ds*\"](https://drive.google.com/file/d/1oICQVSIrDmaMB6R888uyGXRmWcEEQVvy/view?usp=sharing).\n",
    "\n",
    "Then, run the following code to create lmdb file (i.e., generate 'gopro_ds_lmdb' for 'gopro_ds'):"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import lmdb\n",
    "import pickle\n",
    "from os.path import join\n",
    "\n",
    "dataset_name = 'gopro_ds' # replace with the directory name of your dataset\n",
    "data_root = '/home/zhong/Dataset/' # replace with your own path\n",
    "data_path = join(data_root, dataset_name)\n",
    "lmdb_path = join(data_root, dataset_name+'_lmdb')\n",
    "\n",
    "os.makedirs(lmdb_path, exist_ok=True)\n",
    "for dataset_type in ['train', 'valid']:\n",
    "\n",
    "    # create meta-info pkl files for the dataset\n",
    "    path = join(data_path, dataset_type)\n",
    "    seqs = os.listdir(path)\n",
    "    seqs_info = {}\n",
    "    length = 0\n",
    "    for i in range(len(seqs)):\n",
    "        seq_info = {}\n",
    "        seq_info['seq'] = seqs[i]\n",
    "        length_temp = len(os.listdir(join(path,seqs[i],'blur_gamma')))\n",
    "        seq_info['length'] = length_temp\n",
    "        length += length_temp\n",
    "        seqs_info[i] = seq_info\n",
    "    seqs_info['length'] = length\n",
    "    seqs_info['num'] = len(seqs)\n",
    "    f = open(join(lmdb_path,'{}_info_{}.pkl'.format(dataset_name, dataset_type)), 'wb')\n",
    "    pickle.dump(seqs_info, f)\n",
    "    f.close()\n",
    "    \n",
    "    for dataset_label in [dataset_type, '{}_gt'.format(dataset_type)]:\n",
    "        for i in range(seqs_info['num']):\n",
    "            env = lmdb.open(join(lmdb_path, '{}_{}'.format(dataset_name, dataset_label)), map_size=1099511627776)\n",
    "            txn = env.begin(write=True)\n",
    "            if dataset_label.endswith('gt'):\n",
    "                subpath = join(path, seqs_info[i]['seq'], 'sharp')\n",
    "            else:\n",
    "                subpath = join(path, seqs_info[i]['seq'], 'blur_gamma')\n",
    "            imgs = os.listdir(subpath)\n",
    "            nums = [int(img.split('.')[0]) for img in imgs] # make sure your images are named by numbers, e.g., 0001.png.\n",
    "            nums.sort()\n",
    "            gap = nums[0]-0\n",
    "            for img in imgs:\n",
    "                img_path = join(subpath, img)\n",
    "                seq_idx = i\n",
    "                frame_idx = int(img.split('.')[0])-gap\n",
    "                key = '%03d_%08d' % (seq_idx, frame_idx)\n",
    "                data = cv2.imread(img_path)\n",
    "                txn.put(key=key.encode(), value=data)\n",
    "            txn.commit()\n",
    "            env.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% code\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then, use the following code to check if the lmdb file is valid.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% code\n"
    }
   },
   "outputs": [],
   "source": [
    "H,W,C = 540,960,3\n",
    "# tarin set\n",
    "env = lmdb.open(join(lmdb_path, '{}_train'.format(dataset_name)), map_size=1099511627776)\n",
    "env_gt = lmdb.open(join(lmdb_path, '{}_train_gt'.format(dataset_name)), map_size=1099511627776)\n",
    "txn = env.begin()\n",
    "txn_gt = env_gt.begin()\n",
    "seq = 21\n",
    "frame = 39\n",
    "key = '{:03d}_{:08d}'.format(seq, frame)\n",
    "test = txn.get(key.encode())\n",
    "test = np.frombuffer(test, dtype='uint8')\n",
    "test = test.reshape(H,W,C)\n",
    "test_gt = txn_gt.get(key.encode())\n",
    "test_gt = np.frombuffer(test_gt, dtype='uint8')\n",
    "test_gt = test_gt.reshape(H,W,C)\n",
    "plt.imshow(test[:,:,::-1])\n",
    "plt.figure()\n",
    "plt.imshow(test_gt[:,:,::-1])\n",
    "plt.show()\n",
    "env.close()\n",
    "env_gt.close()\n",
    "# valid set\n",
    "env = lmdb.open(join(lmdb_path, '{}_valid'.format(dataset_name)), map_size=1099511627776)\n",
    "env_gt = lmdb.open(join(lmdb_path, '{}_valid_gt'.format(dataset_name)), map_size=1099511627776)\n",
    "txn = env.begin()\n",
    "txn_gt = env_gt.begin()\n",
    "seq = 8\n",
    "frame = 39\n",
    "key = '{:03d}_{:08d}'.format(seq, frame)\n",
    "test = txn.get(key.encode())\n",
    "test = np.frombuffer(test, dtype='uint8')\n",
    "test = test.reshape(H,W,C)\n",
    "test_gt = txn_gt.get(key.encode())\n",
    "test_gt = np.frombuffer(test_gt, dtype='uint8')\n",
    "test_gt = test_gt.reshape(H,W,C)\n",
    "plt.imshow(test[:,:,::-1])\n",
    "plt.figure()\n",
    "plt.imshow(test_gt[:,:,::-1])\n",
    "plt.show()\n",
    "env.close()\n",
    "env_gt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "After generating the lmdb files, you need to creat a python file '[dataset]\\_lmdb.py' under '/data' with the same name as the directory of your lmdb dataset, like 'gopro_ds_lmdb.py'.\n",
    "\n",
    "Then, copy the code of 'gopro_ds_lmdb.py' to your dataset file '[dataset]\\_lmdb.py'.\n",
    "\n",
    "You need to modify the following arguments according to your dataset:\n",
    "\n",
    "```\n",
    "ds_name = 'gopro_ds' # [dataset]\n",
    "self.W = 960 # width of image\n",
    "self.H = 540 # height of image\n",
    "self.C = 3 # channel of image\n",
    "```"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finally, hopefully you can train your dataset by specifying the name of the dataset in cmd or default value in '/para/parameter.py'."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}